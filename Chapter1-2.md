## 《机器学习》第一章和第二章笔记

### 第一章 绪论

#### 1.1 引言

机器学习致力于通过计算的手段，利用经验来改善系统自身的性能。主要研究的内容是在计算机上从数据中产生"模型"的算法，即"学习算法"。学习算法通过对数据的学习，可以建立起模型，并用于对未知数据的预测和决策。机器学习在人工智能领域扮演着重要的角色，其应用涵盖了多个领域，如自然语言处理、计算机视觉、智能推荐系统等。

#### 1.2 基本术语

1. 数据集是一组记录的集合，每条记录描述一个事件或对象，被称为"示例"或"样本"。
2. 反映事件或对象性能或特征的事项称为"属性"或"特征"。
3. 属性上的取值称为属性值。属性张成的空间称为"属性空间"或"样本空间"。
4. 数据集用D={x1,x2,...,xm}表示，每个示例xi=(xi1;xi2;...;xid)是d维样本空间X中的一个向量，其中xi属于X，xij是xi在第j个属性上的取值，d是样本xi的"维数"。
5. 从数据中学习模型的过程称为"学习"或"训练"。学得的模型对应了数据中的潜在规律，称为"假设"，而潜在规律本身称为"真相"。学习的过程是为了找到或逼近真相。模型也被称为"学习器"，是学习算法在给定数据和参数空间上的实例化。
6. 预测离散值的任务称为"分类"，预测连续值的任务称为"回归"。使用带标记信息的示例进行预测任务，通过对训练集进行学习建立从输入空间到输出空间的映射。而"聚类"是将训练集中的数据集自动划分为若干组，每组称为一个"簇"，通常训练样本是不拥有标记信息的。根据训练数据是否有标记信息，学习任务分为"监督学习"和"无监督学习"，前者为分类和回归，后者为聚类。
7. 学得模型适用于新样本的能力称为"泛化能力"，通常假设样本空间中全体样本服从一个未知分布，获得的样本都是独立同分布地从这个分布上采样获得的。

#### 1.3 假设空间

机器学习的过程可以看作在所有假设组成的空间中进行搜索的过程，搜索目标是找到与训练集"匹配"的假设。这里的"假设空间"指的是学习算法所能表示的所有可能的假设的集合。学习算法在这个空间中搜索，找到与训练集最匹配的假设，从而产生一个学习器。

#### 1.4 归纳偏好

机器学习算法在学习过程中对某种类型假设的偏好被称为"归纳偏好"。在学习过程中，学习算法可能遇到多个与训练集一致的假设，但这些假设的复杂程度不同。"奥卡姆剃刀"是一种常用的原则，即在多个与观察一致的假设中，应选取最简单的那个假设作为最终的学习结果。然而，在讨论算法的优劣时，必须针对具体的学习问题，因为不同的问题可能需要不同类型的假设。

#### 1.5 发展历程

第一章中略去了对机器学习发展历程的详细介绍。机器学习的发展可以追溯到20世纪50年代，随着计算机性能的提高和数据量的增加，机器学习得到了迅速发展。经典的机器学习方法包括感知机、决策树、支持向量机等。近年来，深度学习等技术的兴起使得机器学习在许多领域取得了重大突破。

#### 1.6 应用现状

第一章中也略去了对机器学习在各个领域的应用现状的介绍。随着人工智能技术的飞速发展，机器学习在图像识别、自然语言处理、语音识别、智能推荐等领域取得了许多成功的应用。它们不仅在学术研究中发挥着重要作用，也在产业界得到了广泛的应用。

### 第二章 模型评估与选择

#### 2.1 经验误差与过拟合

在机器学习中，我们需要对学习器的性能进行评估。经验误差是指学习器在训练集上的误差，即学习器将训练集中的样本预测结果与其真实结果之间的差异。然而，仅仅关注经验误差是不够的，因为学习器可能在训练集上表现得很好，但对新的未知数据的预测结果却不准确。这种情况被称为"过拟合"。过拟合是指学习器很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，从而导致泛化能力下降。与过拟合相对的是"欠拟合"，这是指学习器对训练样本的一般性质尚未学好，因此在训练集上的表现也较差。

#### 2.2 评估方法

为了准确评估学习器的性能，需要使用测试集来测试学习器对新样本的辨别能力，然后以测试集上的测试误差作为泛化误差的近似。测试集应该与训练集互斥，即测试集中的样本不应该出现在训练集中。

本章介绍了三种常用的评估方法：留出法、交叉验证法和自助法。

1. 留出法：直接将数据集划分为两个互斥的集合，一个作为训练集，另一个作为测试集。要尽量保持数据分布的一致性，以免引入过多的偏差。
2. 交叉验证法：将数据集划分为k个大小相似的互斥子集，每次用k-1个子集的并集作为训练集，余下的作为测试集，重复k次，可以得到k组训练、测试集。这种方法能够更充分地利用数据，但计算成本较高。
3. 自助法：通过有放回地从训练集中抽样得到样本，形成新的训练集，被抽中的样本称为"自助样本"。由于每次抽样后，原始数据集中的一部分样本没有被选中，这样产生的训练集大小与原始数据集相近，可以用于训练学习器，并用原始数据集中没有被选中的样本作为测试集。自助法能够充分利用数据，但也会导致一部分样本在训练集中出现多次，而另一部分样本可能被完全忽略。